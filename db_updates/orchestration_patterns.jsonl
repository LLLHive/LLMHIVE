{"pattern_id": "pte", "name": "Plan-Then-Execute", "category": "planning", "description": "Generate a complete plan before executing any actions. Planner creates step-by-step strategy, execution follows plan.", "when_to_use": ["multi_step_tasks", "clear_dependencies", "research_tasks", "complex_code_changes"], "failure_modes": ["plan_becomes_stale", "over_planning", "missing_edge_cases"], "cost_impact": "+1 LLM call overhead", "latency_impact": "plan_generation_time", "complexity": "medium", "source_url": "https://arxiv.org/abs/2210.03629", "source_title": "ReAct: Synergizing Reasoning and Acting", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "react", "name": "ReAct (Reason-Act-Observe)", "category": "planning", "description": "Interleave reasoning traces with actions. Model reasons, acts, observes result, reasons again.", "when_to_use": ["exploration_tasks", "debugging", "information_gathering", "adaptive_workflows"], "failure_modes": ["infinite_loops", "context_bloat", "premature_path_abandonment"], "cost_impact": "linear_with_steps", "latency_impact": "sequential_calls", "complexity": "medium", "source_url": "https://arxiv.org/abs/2210.03629", "source_title": "ReAct: Synergizing Reasoning and Acting", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "reflexion", "name": "Reflexion", "category": "planning", "description": "After task attempt, model reflects on failures and generates lessons. Subsequent attempts incorporate reflections.", "when_to_use": ["clear_success_signals", "coding_with_tests", "iterative_improvement"], "failure_modes": ["superficial_reflections", "reinforcing_wrong_strategies", "latency_overhead"], "cost_impact": "2-3x for reflection + retry", "latency_impact": "significant", "complexity": "high", "source_url": "https://arxiv.org/abs/2303.11366", "source_title": "Reflexion: Language Agents with Verbal Reinforcement Learning", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "par", "name": "Plan-Act-Reflect", "category": "planning", "description": "Three-phase loop: Plan next action, Execute action, Reflect on result and update plan.", "when_to_use": ["long_horizon_tasks", "agentic_coding", "complex_investigations"], "failure_modes": ["reflection_overhead", "over_reflecting"], "cost_impact": "~1.5x overhead", "latency_impact": "reflection_phase", "complexity": "high", "source_url": "https://docs.anthropic.com/en/docs/build-with-claude/agentic-systems", "source_title": "Anthropic Agentic Systems Guide", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "specialist_selection", "name": "Specialist Selection (Router)", "category": "routing", "description": "Use lightweight classifier/router to select best model based on query characteristics.", "when_to_use": ["production_systems", "cost_constraints", "multi_domain_tasks"], "failure_modes": ["misclassification", "cold_start_new_tasks"], "cost_impact": "+100ms router call, saves on routing", "latency_impact": "router_overhead", "complexity": "low", "source_url": "https://arxiv.org/abs/2406.18665", "source_title": "RouteLLM", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "cascade_fallback", "name": "Cascade/Fallback Tree", "category": "routing", "description": "Start with cheap/fast model. If confidence low or task fails, escalate to more capable model.", "when_to_use": ["high_volume", "cost_sensitive", "simple_majority_queries"], "failure_modes": ["unreliable_confidence", "latency_spikes"], "cost_impact": "30-70% reduction average", "latency_impact": "variable", "complexity": "medium", "source_url": "https://arxiv.org/abs/2305.05176", "source_title": "FrugalGPT", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "judge_critic", "name": "Judge/Critic Pattern", "category": "routing", "description": "One model generates, another model critiques. Can be iterative or single-pass.", "when_to_use": ["high_stakes_outputs", "content_moderation", "factuality_critical"], "failure_modes": ["shared_blind_spots", "cost_overhead"], "cost_impact": "2x minimum", "latency_impact": "critique_phase", "complexity": "medium", "source_url": "https://arxiv.org/abs/2212.08073", "source_title": "Constitutional AI", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "debate", "name": "Multi-Model Debate", "category": "routing", "description": "Multiple models propose solutions, then debate merits. Final answer synthesized.", "when_to_use": ["complex_reasoning", "blind_spot_mitigation"], "failure_modes": ["error_reinforcement", "non_convergence", "high_cost"], "cost_impact": "N×M calls", "latency_impact": "very_high", "complexity": "high", "source_url": "https://arxiv.org/abs/2305.14325", "source_title": "Multiagent Debate for Factuality and Reasoning", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "moa", "name": "Mixture of Agents", "category": "routing", "description": "Multiple models generate in parallel, aggregator synthesizes best answer.", "when_to_use": ["perspective_diversity", "high_stakes_decisions"], "failure_modes": ["poor_aggregation", "expensive"], "cost_impact": "N+1 calls", "latency_impact": "max(generators) + aggregator", "complexity": "high", "source_url": "https://arxiv.org/abs/2406.04692", "source_title": "Mixture-of-Agents", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "cove", "name": "Chain-of-Verification", "category": "verification", "description": "After answer, generate verification questions, answer them, revise based on findings.", "when_to_use": ["factuality_critical", "hallucination_reduction"], "failure_modes": ["missed_issues", "wrong_verification"], "cost_impact": "2-3x tokens", "latency_impact": "verification_phase", "complexity": "medium", "source_url": "https://arxiv.org/abs/2309.11495", "source_title": "Chain-of-Verification Reduces Hallucination", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "test_driven_tool", "name": "Test-Driven Tool Use", "category": "verification", "description": "Generate tests for expected behavior before tool execution. Validate with tests after.", "when_to_use": ["coding_tasks", "data_transformations", "testable_outcomes"], "failure_modes": ["missed_edge_cases", "wrong_tests"], "cost_impact": "test_gen + execution", "latency_impact": "variable", "complexity": "medium", "source_url": "https://www.swebench.com/", "source_title": "SWE-bench Best Practices", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "self_consistency", "name": "Self-Consistency (Majority Voting)", "category": "verification", "description": "Generate multiple solutions independently, select most common answer.", "when_to_use": ["math", "logic", "multiple_choice"], "failure_modes": ["expensive", "consistent_wrong_answers"], "cost_impact": "N× samples", "latency_impact": "parallelizable", "complexity": "low", "source_url": "https://arxiv.org/abs/2203.11171", "source_title": "Self-Consistency Improves Chain of Thought", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "rag", "name": "Standard RAG", "category": "retrieval", "description": "Retrieve relevant documents, include in context, generate grounded answer.", "when_to_use": ["knowledge_intensive", "up_to_date_info", "domain_specific"], "failure_modes": ["missed_docs", "context_pollution", "over_reliance"], "cost_impact": "retrieval + larger context", "latency_impact": "100-500ms retrieval", "complexity": "low", "source_url": "https://arxiv.org/abs/2005.11401", "source_title": "RAG for Knowledge-Intensive NLP", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "citation_discipline", "name": "Citation Discipline", "category": "retrieval", "description": "Require model to cite sources. Validate citations exist and support claims.", "when_to_use": ["research", "fact_checking", "verifiability"], "failure_modes": ["hallucinated_citations", "unsupported_claims"], "cost_impact": "minimal", "latency_impact": "validation_time", "complexity": "low", "source_url": "https://docs.cohere.com/docs/command-r", "source_title": "Cohere Command-R", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "freshness_aware", "name": "Freshness-Aware Retrieval", "category": "retrieval", "description": "Weight recent documents higher, flag stale knowledge.", "when_to_use": ["current_events", "rapidly_changing_domains"], "failure_modes": ["over_weighting_recency"], "cost_impact": "minimal", "latency_impact": "minimal", "complexity": "low", "source_url": "https://blog.perplexity.ai/", "source_title": "Perplexity Engineering", "retrieved_at": "2024-12-20", "confidence": "medium"}
{"pattern_id": "self_rag", "name": "Agentic RAG (Self-RAG)", "category": "retrieval", "description": "Model decides when to retrieve, what to retrieve, evaluates retrieval helpfulness.", "when_to_use": ["complex_queries", "adaptive_retrieval", "multi_step_gathering"], "failure_modes": ["over_under_retrieval", "suboptimal_decisions"], "cost_impact": "variable", "latency_impact": "variable", "complexity": "high", "source_url": "https://arxiv.org/abs/2310.11511", "source_title": "Self-RAG", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "quality_tool_defs", "name": "High-Quality Tool Definitions", "category": "tool_use", "description": "Craft tool descriptions with clear semantics, parameter constraints, examples, error conditions.", "when_to_use": ["always"], "failure_modes": ["poor_descriptions_cause_misuse"], "cost_impact": "none", "latency_impact": "none", "complexity": "low", "source_url": "https://platform.openai.com/docs/guides/function-calling", "source_title": "OpenAI Function Calling Best Practices", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "tool_examples", "name": "Tool-Use Examples in Schema", "category": "tool_use", "description": "Include example tool calls in definition when model supports it.", "when_to_use": ["complex_tools", "non_obvious_formats"], "failure_modes": ["pattern_bias"], "cost_impact": "tokens_in_system", "latency_impact": "minimal", "complexity": "low", "source_url": "https://docs.anthropic.com/en/docs/build-with-claude/tool-use", "source_title": "Anthropic Tool Use", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "tool_search", "name": "Tool Search / Deferred Loading", "category": "tool_use", "description": "Semantic search to find relevant tools instead of loading all upfront.", "when_to_use": ["large_tool_libraries", "context_limits"], "failure_modes": ["missed_relevant_tools"], "cost_impact": "context_savings", "latency_impact": "retrieval_step", "complexity": "medium", "source_url": "https://arxiv.org/abs/2305.15334", "source_title": "Gorilla LLM", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "programmatic_calling", "name": "Programmatic Tool Calling", "category": "tool_use", "description": "Model writes code to orchestrate tool calls rather than individual function calls.", "when_to_use": ["complex_workflows", "batch_operations", "conditional_logic"], "failure_modes": ["code_bugs", "debugging_difficulty"], "cost_impact": "reduces_roundtrips", "latency_impact": "batch_execution", "complexity": "high", "source_url": "https://docs.anthropic.com/en/docs/agents-and-tools/computer-use", "source_title": "Anthropic Computer Use", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "output_summarization", "name": "Tool Output Summarization", "category": "tool_use", "description": "Summarize verbose tool outputs before adding to context.", "when_to_use": ["large_tool_outputs", "logs", "api_responses"], "failure_modes": ["lost_details"], "cost_impact": "summarization_call", "latency_impact": "summarization_time", "complexity": "medium", "source_url": "https://python.langchain.com/docs/modules/agents/", "source_title": "LangChain Agents", "retrieved_at": "2024-12-20", "confidence": "medium"}
{"pattern_id": "input_sanitization", "name": "Input Sanitization", "category": "security", "description": "Validate and sanitize user inputs before passing to LLM or tools.", "when_to_use": ["always_production"], "failure_modes": ["incomplete_sanitization"], "cost_impact": "minimal", "latency_impact": "minimal", "complexity": "low", "source_url": "https://owasp.org/www-project-top-10-for-large-language-model-applications/", "source_title": "OWASP LLM Top 10", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "injection_resistance", "name": "Prompt Injection Resistance", "category": "security", "description": "Delimit user content, use system prompts for behavior, validate outputs.", "when_to_use": ["user_facing_apps"], "failure_modes": ["sophisticated_attacks"], "cost_impact": "minimal", "latency_impact": "minimal", "complexity": "medium", "source_url": "https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering", "source_title": "Anthropic Prompt Engineering", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "tool_allowlisting", "name": "Tool Allowlisting", "category": "security", "description": "Only expose tools user permission level allows. Validate against allowlist.", "when_to_use": ["multi_tenant", "varying_permissions"], "failure_modes": ["overly_permissive"], "cost_impact": "minimal", "latency_impact": "minimal", "complexity": "low", "source_url": "https://modelcontextprotocol.io/", "source_title": "MCP Security Patterns", "retrieved_at": "2024-12-20", "confidence": "medium"}
{"pattern_id": "output_validation", "name": "Output Validation / Schema Enforcement", "category": "security", "description": "Validate LLM outputs against expected schemas. Reject or retry invalid.", "when_to_use": ["structured_output", "api_integrations"], "failure_modes": ["valid_but_incorrect"], "cost_impact": "minimal", "latency_impact": "validation_time", "complexity": "low", "source_url": "https://platform.openai.com/docs/guides/structured-outputs", "source_title": "OpenAI Structured Outputs", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "sandbox_execution", "name": "Sandboxed Execution", "category": "security", "description": "Execute model-generated code in isolated sandbox with resource limits.", "when_to_use": ["code_execution", "agentic_coding"], "failure_modes": ["sandbox_escape_rare"], "cost_impact": "container_overhead", "latency_impact": "container_startup", "complexity": "medium", "source_url": "https://e2b.dev/docs", "source_title": "E2B Sandbox", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "cot", "name": "Chain-of-Thought", "category": "reasoning", "description": "Prompt model to show reasoning steps before final answer.", "when_to_use": ["math", "logic", "multi_step"], "failure_modes": ["plausible_wrong_reasoning"], "cost_impact": "2-5x output tokens", "latency_impact": "longer_generation", "complexity": "low", "source_url": "https://arxiv.org/abs/2201.11903", "source_title": "Chain-of-Thought Prompting", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "tot", "name": "Tree-of-Thought", "category": "reasoning", "description": "Explore multiple reasoning paths, evaluate intermediate states, backtrack if needed.", "when_to_use": ["complex_problems", "multiple_approaches"], "failure_modes": ["expensive", "non_convergence"], "cost_impact": "O(branching×depth)", "latency_impact": "very_high", "complexity": "high", "source_url": "https://arxiv.org/abs/2305.10601", "source_title": "Tree of Thoughts", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "step_back", "name": "Step-Back Prompting", "category": "reasoning", "description": "Before answering, ask model to identify underlying principle or higher-level concept.", "when_to_use": ["science", "math", "conceptual"], "failure_modes": ["irrelevant_principle"], "cost_impact": "+1 call", "latency_impact": "one_additional_call", "complexity": "low", "source_url": "https://arxiv.org/abs/2310.06117", "source_title": "Step-Back Prompting", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "decomposition", "name": "Decomposition (Least-to-Most)", "category": "reasoning", "description": "Break complex problem into simpler sub-problems, solve sequentially.", "when_to_use": ["complex_multi_part", "compositional_tasks"], "failure_modes": ["missed_dependencies"], "cost_impact": "multiple_calls_simpler_each", "latency_impact": "sequential", "complexity": "medium", "source_url": "https://arxiv.org/abs/2205.10625", "source_title": "Least-to-Most Prompting", "retrieved_at": "2024-12-20", "confidence": "high"}
{"pattern_id": "extended_thinking", "name": "Extended Thinking / Budget Forcing", "category": "reasoning", "description": "Force model to use more compute for reasoning via effort parameters or extended thinking.", "when_to_use": ["hard_problems", "quality_over_speed"], "failure_modes": ["diminishing_returns", "expensive"], "cost_impact": "linear_with_budget", "latency_impact": "linear_with_budget", "complexity": "low", "source_url": "https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking", "source_title": "Anthropic Extended Thinking", "retrieved_at": "2024-12-20", "confidence": "high"}


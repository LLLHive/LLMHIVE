*** Begin Patch
*** Update File: llmhive/src/llmhive/app/config.py
@@ class Settings(BaseSettings):
     openai_timeout_seconds: float = Field(default=45.0, alias="OPENAI_TIMEOUT_SECONDS")
+    # API keys for additional providers.  These keys can be set in the environment
+    # or .env file.  They are optional; if not provided the corresponding provider
+    # will not be configured.
+    anthropic_api_key: str | None = Field(default=None, alias="ANTHROPIC_API_KEY")
+    grok_api_key: str | None = Field(default=None, alias="GROK_API_KEY")
+    gemini_api_key: str | None = Field(default=None, alias="GEMINI_API_KEY")
+    deepseek_api_key: str | None = Field(default=None, alias="DEEPSEEK_API_KEY")
+    manus_api_key: str | None = Field(default=None, alias="MANUS_API_KEY")
+    # Timeouts for the additional providers
+    anthropic_timeout_seconds: float = Field(default=45.0, alias="ANTHROPIC_TIMEOUT_SECONDS")
+    grok_timeout_seconds: float = Field(default=45.0, alias="GROK_TIMEOUT_SECONDS")
+    gemini_timeout_seconds: float = Field(default=45.0, alias="GEMINI_TIMEOUT_SECONDS")
+    deepseek_timeout_seconds: float = Field(default=45.0, alias="DEEPSEEK_TIMEOUT_SECONDS")
+    manus_timeout_seconds: float = Field(default=45.0, alias="MANUS_TIMEOUT_SECONDS")
@@ class Settings(BaseSettings):
-    default_models: List[str] = Field(
-        default_factory=lambda: ["gpt-4o-mini", "gpt-3.5-turbo"], alias="DEFAULT_MODELS"
-    )
+    default_models: List[str] = Field(
+        default_factory=lambda: [
+            "gpt-4o-mini",
+            "gpt-3.5-turbo",
+            "claude-3-sonnet-20240229",
+            "grok-1",
+            "gemini-pro",
+            "deepseek-chat",
+            "manus",
+        ],
+        alias="DEFAULT_MODELS",
+    )
*** End Patch
*** End Patch
*** Begin Patch
*** Update File: llmhive/src/llmhive/app/orchestrator.py
@@ class Orchestrator:
-    def _default_providers(self) -> Dict[str, LLMProvider]:
-        mapping: Dict[str, LLMProvider] = {}
-        try:
-            mapping["openai"] = OpenAIProvider()
-        except ProviderNotConfiguredError:
-            logger.info("OpenAI provider not configured; falling back to stub provider.")
-        if "openai" not in mapping:
-            mapping["stub"] = StubProvider()
-        else:
-            mapping.setdefault("stub", StubProvider())
-        return mapping
+    def _default_providers(self) -> Dict[str, LLMProvider]:
+        """
+        Instantiate and return the default LLM providers based on configuration.
+
+        Providers are only included if their corresponding API keys are set
+        in the settings.  The `openai` provider is included when the OpenAI
+        API key is configured; otherwise, the stub provider is used.  Additional
+        providers (Anthropic, Grok, Gemini, DeepSeek, Manus) are added if
+        their API keys are present in settings.
+        """
+        mapping: Dict[str, LLMProvider] = {}
+        # Always try to configure OpenAI provider first
+        try:
+            if settings.openai_api_key:
+                mapping["openai"] = OpenAIProvider(
+                    api_key=settings.openai_api_key,
+                    timeout=settings.openai_timeout_seconds,
+                )
+        except ProviderNotConfiguredError:
+            logger.info("OpenAI provider not configured; falling back to stub provider.")
+        # Conditionally include Anthropic provider
+        try:
+            if settings.anthropic_api_key:
+                mapping["anthropic"] = AnthropicProvider(
+                    api_key=settings.anthropic_api_key,
+                    timeout=settings.anthropic_timeout_seconds,
+                )
+        except Exception:
+            logger.warning("Anthropic provider not configured; skipping.")
+        # Conditionally include Grok provider
+        try:
+            if settings.grok_api_key:
+                mapping["grok"] = GrokProvider(
+                    api_key=settings.grok_api_key,
+                    timeout=settings.grok_timeout_seconds,
+                )
+        except Exception:
+            logger.warning("Grok provider not configured; skipping.")
+        # Conditionally include Gemini provider
+        try:
+            if settings.gemini_api_key:
+                mapping["gemini"] = GeminiProvider(
+                    api_key=settings.gemini_api_key,
+                    timeout=settings.gemini_timeout_seconds,
+                )
+        except Exception:
+            logger.warning("Gemini provider not configured; skipping.")
+        # Conditionally include DeepSeek provider
+        try:
+            if settings.deepseek_api_key:
+                mapping["deepseek"] = DeepSeekProvider(
+                    api_key=settings.deepseek_api_key,
+                    timeout=settings.deepseek_timeout_seconds,
+                )
+        except Exception:
+            logger.warning("DeepSeek provider not configured; skipping.")
+        # Conditionally include Manus provider
+        try:
+            if settings.manus_api_key:
+                mapping["manus"] = ManusProvider(
+                    api_key=settings.manus_api_key,
+                    timeout=settings.manus_timeout_seconds,
+                )
+        except Exception:
+            logger.warning("Manus provider not configured; skipping.")
+        # Always provide a stub provider for fallback
+        mapping.setdefault("stub", StubProvider())
+        return mapping
@@ class Orchestrator:
-    def _select_provider(self, model: str) -> LLMProvider:
-        if model.startswith("gpt") and "openai" in self.providers:
-            return self.providers["openai"]
-        return self.providers.get("stub", StubProvider())
+    def _select_provider(self, model: str) -> LLMProvider:
+        """
+        Select the appropriate provider based on the model name prefix.
+
+        This logic ensures that models from different providers are routed to
+        their corresponding provider instances.  If no provider matches, fall
+        back to the stub provider.
+        """
+        m = model.lower()
+        # OpenAI models start with "gpt"
+        if m.startswith("gpt") and "openai" in self.providers:
+            return self.providers["openai"]
+        # Anthropic models start with "claude"
+        if m.startswith("claude") and "anthropic" in self.providers:
+            return self.providers["anthropic"]
+        # Grok models start with "grok"
+        if m.startswith("grok") and "grok" in self.providers:
+            return self.providers["grok"]
+        # Gemini models start with "gemini"
+        if m.startswith("gemini") and "gemini" in self.providers:
+            return self.providers["gemini"]
+        # DeepSeek models start with "deepseek"
+        if m.startswith("deepseek") and "deepseek" in self.providers:
+            return self.providers["deepseek"]
+        # Manus models start with "manus"
+        if m.startswith("manus") and "manus" in self.providers:
+            return self.providers["manus"]
+        # Default fallback: stub
+        return self.providers.get("stub", StubProvider())
*** End Patch
*** End Patch

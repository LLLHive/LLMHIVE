{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:38:10.688722", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/0", "index": 1, "task_id": "HumanEval/0", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 24691, "cost_usd": 0.023145, "raw_response": "    for i in range(len(numbers)):\n        for j in range(i + 1, len(numbers)):\n            if abs(numbers[i] - numbers[j]) < threshold:\n                return True\n    return False\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:38:10.687778"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:38:36.876967", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/1", "index": 2, "task_id": "HumanEval/1", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 18694, "cost_usd": 0.020200000000000003, "raw_response": "    import string\n    clean_string = paren_string.replace(' ', '')\n    groups = []\n    balance = 0\n    current_group = []\n\n    for char in clean_string:\n        if char == '(':\n            if balance == 0 and current_group:\n                groups.append(''.join(current_group))\n                current_group = []\n            current_group.append(char)\n            balance += 1\n        elif char == ')':\n            current_group.append(char)\n            balance -= 1\n            if balance == 0:\n    ", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:38:36.875888"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:39:24.561102", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/2", "index": 3, "task_id": "HumanEval/2", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 40511, "cost_usd": 0.042495000000000005, "raw_response": "    import math\n    return number - math.floor(number)\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:39:24.560100"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:41:03.209193", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/3", "index": 4, "task_id": "HumanEval/3", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 90218, "cost_usd": 0.09486, "raw_response": "    balance = 0\n    for op in operations:\n        balance += op\n        if balance < 0:\n            return True\n    return False\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:41:03.207657"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:41:35.920374", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/4", "index": 5, "task_id": "HumanEval/4", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 25670, "cost_usd": 0.024370000000000003, "raw_response": "    if not numbers:\n        return 0.0\n\n    mean = sum(numbers) / len(numbers)\n    absolute_deviations = [abs(x - mean) for x in numbers]\n    mad = sum(absolute_deviations) / len(absolute_deviations)\n    return mad\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:41:35.919318"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:42:11.529518", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/5", "index": 6, "task_id": "HumanEval/5", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 28703, "cost_usd": 0.030600000000000002, "raw_response": "    if not numbers:\n        return []\n    result: List[int] = []\n    for i, num in enumerate(numbers):\n        result.append(num)\n        if i < len(numbers) - 1:\n            result.append(delimeter)\n    return result\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:42:11.529072"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:42:37.679139", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/6", "index": 7, "task_id": "HumanEval/6", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 19055, "cost_usd": 0.018904999999999998, "raw_response": "    import string\n    results = []\n    groups = paren_string.split()\n\n    for group in groups:\n        max_depth = 0\n        current_depth = 0\n\n        for char in group:\n            if char == '(':\n                current_depth += 1\n                max_depth = max(max_depth, current_depth)\n            elif char == ')':\n                current_depth -= 1\n\n        results.append(max_depth)\n\n    return results\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:42:37.678797"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:43:09.401646", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/7", "index": 8, "task_id": "HumanEval/7", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 24743, "cost_usd": 0.031535, "raw_response": "    return [s for s in strings if substring in s]\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:43:09.401273"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:44:38.056943", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/8", "index": 9, "task_id": "HumanEval/8", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 81610, "cost_usd": 0.11449999999999999, "raw_response": "    total = 0\n    product = 1\n    for n in numbers:\n        total += n\n        product *= n\n    return total, product\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:44:38.056620"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:45:18.844350", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/9", "index": 10, "task_id": "HumanEval/9", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 33754, "cost_usd": 0.037755, "raw_response": "    result: List[int] = []\n    current_max = None\n    for n in numbers:\n        if current_max is None or n > current_max:\n            current_max = n\n        result.append(current_max)\n    return result\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:45:18.843968"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:45:50.180782", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/10", "index": 11, "task_id": "HumanEval/10", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 24457, "cost_usd": 0.020909999999999998, "raw_response": "    if not string:\n        return ''\n\n    for i in range(len(string)):\n        if is_palindrome(string[i:]):\n            return string + string[:i][::-1]\n\n    return string + string[::-1]\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:45:50.180444"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:46:28.948517", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/11", "index": 12, "task_id": "HumanEval/11", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 31783, "cost_usd": 0.029795000000000002, "raw_response": "    if len(a) != len(b):\n        raise ValueError(\"Inputs must be of equal length.\")\n    return ''.join('1' if x != y else '0' for x, y in zip(a, b))\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:46:28.948177"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:47:14.945108", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/12", "index": 13, "task_id": "HumanEval/12", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 39059, "cost_usd": 0.033714999999999995, "raw_response": "    if not strings:\n        return None\n    best = strings[0]\n    best_len = len(best)\n    for s in strings[1:]:\n        l = len(s)\n        if l > best_len:\n            best = s\n            best_len = l\n    return best\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:47:14.944779"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:48:08.496774", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/13", "index": 14, "task_id": "HumanEval/13", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 46580, "cost_usd": 0.025365, "raw_response": "    a, b = abs(a), abs(b)\n    while b:\n        a, b = b, a % b\n    return a\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:48:08.495577"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:49:40.249012", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/14", "index": 15, "task_id": "HumanEval/14", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 83615, "cost_usd": 0.064535, "raw_response": "    return [string[:i] for i in range(1, len(string) + 1)]\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:49:40.247946"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:50:42.691143", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/15", "index": 16, "task_id": "HumanEval/15", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 55455, "cost_usd": 0.07645, "raw_response": "    return ' '.join(str(i) for i in range(n + 1))\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:50:42.690764"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:52:14.596968", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/16", "index": 17, "task_id": "HumanEval/16", "is_correct": false, "passed": false, "attempt": 3, "failure_type": "logic", "error": "all_attempts_failed", "last_error": "failed: module 'string' has no attribute 'lower'", "raw_response": "    import string\n    return len(set(string.lower()))\n", "latency_ms": 70633, "cost_usd": 0.074965, "retry_count": 2, "ts": "2026-02-23T01:52:14.595955"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:53:39.530905", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/17", "index": 18, "task_id": "HumanEval/17", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 77385, "cost_usd": 0.058714999999999996, "raw_response": "    import string\n    mapping = {'o': 4, 'o|': 2, '.|': 1}\n    if not music_string or not music_string.strip():\n        return []\n    result = []\n    for token in music_string.split():\n        if token not in mapping:\n            raise ValueError(f\"Unknown note symbol: {token}\")\n        result.append(mapping[token])\n    return result\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:53:39.529504"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:55:12.857909", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/18", "index": 19, "task_id": "HumanEval/18", "is_correct": false, "passed": false, "attempt": 3, "failure_type": "runtime", "error": "all_attempts_failed", "last_error": "failed: invalid syntax (<string>, line 14)", "raw_response": "    import string\n\n    Requirement 1: Provide a corrected function code for the implementation of `how_many_times` that counts overlapping occurrences of a substring within a string\n\n\n    ### Requirement 1: Provide a corrected function code for the implementation of `how_many_times`\n", "latency_ms": 71903, "cost_usd": 0.07400999999999999, "retry_count": 2, "ts": "2026-02-23T01:55:12.856370"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:55:55.468728", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/19", "index": 20, "task_id": "HumanEval/19", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 35543, "cost_usd": 0.03669, "raw_response": "    names = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n    if not numbers:\n        return ''\n    order = {name: i for i, name in enumerate(names)}\n    words = numbers.split()\n    words.sort(key=lambda w: order[w])\n    return ' '.join(words)\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:55:55.467248"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:56:25.695502", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/20", "index": 21, "task_id": "HumanEval/20", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 23063, "cost_usd": 0.023379999999999998, "raw_response": "    min_diff = float('inf')\n    closest_pair = (numbers[0], numbers[1])\n\n    # Sort the numbers to find closest pairs easily\n    sorted_numbers = sorted(numbers)\n\n    # Check the difference between each pair of consecutive numbers\n    for i in range(len(sorted_numbers) - 1):\n        diff = abs(sorted_numbers[i] - sorted_numbers[i + 1])\n        if diff < min_diff:\n            min_diff = diff\n            closest_pair = (sorted_numbers[i], sorted_numbers[i + 1])\n\n    return closest_pair\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:56:25.694626"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:57:14.375428", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/21", "index": 22, "task_id": "HumanEval/21", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 41579, "cost_usd": 0.04759, "raw_response": "    mn = min(numbers)\n    mx = max(numbers)\n    rng = mx - mn\n    if rng == 0:\n        return [0.0 for _ in numbers]\n    return [(x - mn) / rng for x in numbers]\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:57:14.374235"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:58:03.067494", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/22", "index": 23, "task_id": "HumanEval/22", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 41649, "cost_usd": 0.041285, "raw_response": "    return [v for v in values if type(v) is int]\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:58:03.067148"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T01:58:45.527053", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/23", "index": 24, "task_id": "HumanEval/23", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 35457, "cost_usd": 0.018835, "raw_response": "    return len(string)\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T01:58:45.526091"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:00:12.474841", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/24", "index": 25, "task_id": "HumanEval/24", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 79322, "cost_usd": 0.089115, "raw_response": "    if n <= 1:\n        return 0\n    for i in range(n // 2, 0, -1):\n        if n % i == 0:\n            return i\n    return 0.\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:00:12.473738"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:01:43.148611", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/25", "index": 26, "task_id": "HumanEval/25", "is_correct": false, "passed": false, "attempt": 3, "failure_type": "runtime", "error": "all_attempts_failed", "last_error": "failed: invalid syntax (<string>, line 16)", "raw_response": "    ### Step 1: Define Variables\n    Let:\n    - `n = integer to be factorized`\n    - `factors` = list of prime factors of `n` in order from smallest to largest\n\n    ### Step 2: Set Up Equations\n    To factorize the integer `n`, we need to find all prime numbers that can be multiplied together to yield `n`, accounting for the multiplicity of each prime factor:\n    - The process begins by checking divisibility, starting from the smallest prime number (2), and continues to divide `n` by its factors", "latency_ms": 68236, "cost_usd": 0.055335, "retry_count": 2, "ts": "2026-02-23T02:01:43.146979"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:02:42.581591", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/26", "index": 27, "task_id": "HumanEval/26", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 52407, "cost_usd": 0.042245000000000005, "raw_response": "    counts = {}\n    for n in numbers:\n        counts[n] = counts.get(n, 0) + 1\n    return [n for n in numbers if counts[n] == 1]\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:02:42.581235"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:04:53.251574", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/27", "index": 28, "task_id": "HumanEval/27", "is_correct": false, "passed": false, "attempt": 3, "failure_type": "logic", "error": "all_attempts_failed", "last_error": "failed: module 'string' has no attribute 'swapcase'", "raw_response": "    import string\n    return string.swapcase()\n", "latency_ms": 109641, "cost_usd": 0.101295, "retry_count": 2, "ts": "2026-02-23T02:04:53.250804"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:05:35.202555", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/28", "index": 29, "task_id": "HumanEval/28", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 34992, "cost_usd": 0.02884, "raw_response": "    return ''.join(strings)\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:05:35.202155"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:06:24.544011", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/29", "index": 30, "task_id": "HumanEval/29", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 42398, "cost_usd": 0.03547, "raw_response": "    return [s for s in strings if s.startswith(prefix)]\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:06:24.543554"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:08:13.434256", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/30", "index": 31, "task_id": "HumanEval/30", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 100374, "cost_usd": 0.10525000000000001, "raw_response": "    return [x for x in l if x > 0]\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:08:13.433074"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:08:47.743820", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/31", "index": 32, "task_id": "HumanEval/31", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 26121, "cost_usd": 0.020515000000000002, "raw_response": "    if n <= 1:\n        return False\n    for i in range(2, int(n**0.5) + 1):\n        if n % i == 0:\n            return False\n    return True\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:08:47.699923"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:14:34.159130", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/33", "index": 34, "task_id": "HumanEval/33", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 27551, "cost_usd": 0.022025, "raw_response": "    sorted_third = sorted(l[i] for i in range(len(l)) if i % 3 == 0)\n    result = l[:]\n\n    j = 0\n    for i in range(len(result)):\n        if i % 3 == 0:\n            result[i] = sorted_third[j]\n            j += 1\n\n    return result\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:14:34.158036"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:15:07.109306", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/34", "index": 35, "task_id": "HumanEval/34", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 25745, "cost_usd": 0.02693, "raw_response": "    return sorted(set(l))\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:15:07.108913"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:15:46.208614", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/35", "index": 36, "task_id": "HumanEval/35", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 31740, "cost_usd": 0.027285, "raw_response": "    if not l:\n        raise ValueError(\"max_element() arg is an empty list\")\n    max_val = l[0]\n    for item in l[1:]:\n        if item > max_val:\n            max_val = item\n    return max_val\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:15:46.208265"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:16:35.382454", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/36", "index": 37, "task_id": "HumanEval/36", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 42165, "cost_usd": 0.04574, "raw_response": "    count = 0\n    for i in range(n):\n        if i % 11 == 0 or i % 13 == 0:\n            count += str(i).count('7')\n    return count\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:16:35.382143"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:17:07.490052", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/37", "index": 38, "task_id": "HumanEval/37", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 25064, "cost_usd": 0.02174, "raw_response": "    even_indices = sorted(l[i] for i in range(0, len(l), 2))\n    result = l[:]\n    result[::2] = even_indices\n    return result\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:17:07.489054"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:17:43.152807", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/38", "index": 39, "task_id": "HumanEval/38", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 28159, "cost_usd": 0.023875, "raw_response": "    groups = [s[(3 * i):min((3 * i + 3), len(s))] for i in range((len(s) + 2) // 3)]\n    groups = [(group[-1] + group[:-1]) if len(group) == 3 else group for group in groups]\n    return \"\".join(groups)\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:17:43.151769"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:18:19.041108", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/39", "index": 40, "task_id": "HumanEval/39", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 28825, "cost_usd": 0.020795, "raw_response": "    def prime_fib(num):\n        if num < 2:\n            return False\n        for i in range(2, int(num**0.5) + 1):\n            if num % i == 0:\n                return False\n        return True\n\n\n    fib_nums = []\n    a, b = 0, 1\n    while len(fib_nums) < n:\n        a, b = b, a + b\n        if prime_fib(a):\n            fib_nums.append(a)\n\n    return fib_nums[n - 1]\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:18:19.040738"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:18:46.542162", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/40", "index": 41, "task_id": "HumanEval/40", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 20402, "cost_usd": 0.02134, "raw_response": "    n = len(l)\n    for i in range(n):\n        for j in range(i + 1, n):\n            for k in range(j + 1, n):\n                if l[i] + l[j] + l[k] == 0:\n                    return True\n    return False\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:18:46.540611"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:19:27.576512", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/41", "index": 42, "task_id": "HumanEval/41", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 33873, "cost_usd": 0.034615, "raw_response": "    if n <= 0:\n        return 0\n    return n * n\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:19:27.575464"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:20:14.974711", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/42", "index": 43, "task_id": "HumanEval/42", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 40305, "cost_usd": 0.03008, "raw_response": "    return [x + 1 for x in l]\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:20:14.974372"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:21:08.844921", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/43", "index": 44, "task_id": "HumanEval/43", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 46788, "cost_usd": 0.05092000000000001, "raw_response": "    for i in range(len(l)):\n        for j in range(i + 1, len(l)):\n            if l[i] + l[j] == 0:\n                return True\n    return False\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:21:08.843920"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:22:26.984593", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/44", "index": 45, "task_id": "HumanEval/44", "is_correct": false, "passed": false, "attempt": 3, "failure_type": "runtime", "error": "all_attempts_failed", "last_error": "failed: invalid syntax (<string>, line 33)", "raw_response": "    if base < 2 or base > 9:\n        raise ValueError(\"Base must be between 2 and 9 inclusive\")\n    if x == 0:\n        return \"0\"\n\n    negative = x < 0\n    n = abs(x)\n    digits = []\n\n    while n > 0:\n        digits.append(str(n % base))\n        n //= base\n\n    result = \"\".join(reversed(digits))\n\n    if negative:\n        result = \"-\" + result\n\n    return result\n    This function checks for base validity, handles the special case of zero, processes the number to convert it to the desired base, an", "latency_ms": 56999, "cost_usd": 0.058335, "retry_count": 2, "ts": "2026-02-23T02:22:26.983831"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:23:15.986837", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/45", "index": 46, "task_id": "HumanEval/45", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 41958, "cost_usd": 0.039605, "raw_response": "    return 0.5 * a * h\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:23:15.986016"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:23:47.254888", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/46", "index": 47, "task_id": "HumanEval/46", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 22790, "cost_usd": 0.02611, "raw_response": "    if n == 0: return 0\n    elif n == 1: return 0\n    elif n == 2: return 2\n    elif n == 3: return 0\n\n    fib = [0] * (n + 1)\n    fib[0], fib[1], fib[2], fib[3] = 0, 0, 2, 0\n\n    for i in range(4, n + 1):\n        fib[i] = fib[i-1] + fib[i-2] + fib[i-3] + fib[i-4]\n\n    return fib[n]\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:23:47.254043"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:24:17.219108", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/47", "index": 48, "task_id": "HumanEval/47", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 22853, "cost_usd": 0.023899999999999998, "raw_response": "    if not l:\n        return None\n    l.sort()\n    n = len(l)\n    mid = n // 2\n    if n % 2 == 0:\n        return (l[mid - 1] + l[mid]) / 2\n    else:\n        return l[mid]\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:24:17.218048"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:24:53.025354", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/48", "index": 49, "task_id": "HumanEval/48", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 27332, "cost_usd": 0.026985, "raw_response": "    return text == text[::-1]\n", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:24:53.024611"}
{"commit": "41594f035", "branch": "fix/enterprise-latency-policy-2026-02-20", "timestamp": "2026-02-23T02:25:43.104664", "environment": {"cloud_revision": "local", "runtime_minutes_cap": "180", "cost_cap_usd": "5.00", "tier": "elite", "seed": "42"}, "category": "HumanEval", "question_id": "HumanEval/49", "index": 50, "task_id": "HumanEval/49", "is_correct": true, "passed": true, "attempt": 1, "latency_ms": 42688, "cost_usd": 0.045925, "raw_response": "    if p == 0:\n        raise ZeroDivisionError(\"modulo by zero\")\n    if n >= 0:\n        return pow(2, n, p)\n    # Handle negative exponent: compute modular inverse of 2 mod p, then raise to -n\n    def modp(a, b):\n        if b == 0:\n            return (a, 1, 0)\n        g, x1, y1 = modp(b, a % b)\n        return (g, y1, x1 - (a // b) * y1)\n    a = 2 % p\n    g, x, _ = modp(a, p)\n    if g != 1:\n        raise ValueError(\"inverse of 2 modulo p does not exist\")\n    inv2 = x % p\n    return pow(inv2, -n, ", "failure_type": null, "retry_count": 0, "ts": "2026-02-23T02:25:43.103182"}

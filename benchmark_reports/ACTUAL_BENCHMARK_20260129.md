# üèÜ LLMHive Actual Benchmark Results ‚Äî January 29, 2026

## Test Configuration

- **Benchmark Date:** 2026-01-29T12:13:13.463159
- **API Endpoint:** https://llmhive-orchestrator-792354158895.us-east1.run.app
- **Test Method:** Live API calls with keyword/pattern evaluation
- **Overall Pass Rate:** 7/29 (24.1%)

---

## 1. General Reasoning ‚Äî GPQA Diamond (PhD-Level Science)

| Metric | Value |
|--------|-------|
| Pass Rate | **40.0%** (2/5) |
| Avg Score | **77.8%** |
| Avg Latency | 8345ms |

<details>
<summary>Test Details</summary>

| Test ID | Category | Score | Status |
|---------|----------|-------|--------|
| gr_001 | PhD-Level Physics | 0.0% | ‚ùå FAIL |
| gr_002 | PhD-Level Chemistry | 0.0% | ‚ùå FAIL |
| gr_003 | PhD-Level Mathematics | 100.0% | ‚úÖ PASS |
| gr_004 | PhD-Level Biology | 33.3% | ‚ö†Ô∏è PARTIAL |
| gr_005 | PhD-Level Computer Science | 100.0% | ‚úÖ PASS |

</details>

---

## 2. Coding ‚Äî SWE-Bench Verified (Real GitHub Issues)

| Metric | Value |
|--------|-------|
| Pass Rate | **80.0%** (4/5) |
| Avg Score | **93.8%** |
| Avg Latency | 14499ms |

<details>
<summary>Test Details</summary>

| Test ID | Category | Score | Status |
|---------|----------|-------|--------|
| code_001 | Algorithm Implementation | 100.0% | ‚úÖ PASS |
| code_002 | Data Structures | 75.0% | ‚úÖ PASS |
| code_003 | Database | 0.0% | ‚ùå FAIL |
| code_004 | Frontend | 100.0% | ‚úÖ PASS |
| code_005 | DevOps | 100.0% | ‚úÖ PASS |

</details>

---

## 3. Math ‚Äî AIME 2024 (Competition Mathematics)

| Metric | Value |
|--------|-------|
| Pass Rate | **20.0%** (1/5) |
| Avg Score | **100.0%** |
| Avg Latency | 1815ms |

<details>
<summary>Test Details</summary>

| Test ID | Category | Score | Status |
|---------|----------|-------|--------|
| math_001 | Number Theory | 0.0% | ‚ùå FAIL |
| math_002 | Geometry | 0.0% | ‚ùå FAIL |
| math_003 | Calculus | 100.0% | ‚úÖ PASS |
| math_004 | Combinatorics | 0.0% | ‚ùå FAIL |
| math_005 | Algebra | 0.0% | ‚ùå FAIL |

</details>

---

## 4. Multilingual Understanding ‚Äî MMMLU (14 Languages)

| Metric | Value |
|--------|-------|
| Pass Rate | **0.0%** (0/5) |
| Avg Score | **0.0%** |
| Avg Latency | 0ms |

<details>
<summary>Test Details</summary>

| Test ID | Category | Score | Status |
|---------|----------|-------|--------|
| ml_001 | Translation | 0.0% | ‚ùå FAIL |
| ml_002 | Chinese Comprehension | 0.0% | ‚ùå FAIL |
| ml_003 | French Comprehension | 0.0% | ‚ùå FAIL |
| ml_004 | Japanese Generation | 0.0% | ‚ùå FAIL |
| ml_005 | German Generation | 0.0% | ‚ùå FAIL |

</details>

---

## 5. Long-Context Handling ‚Äî Context Window Size

| Metric | Value |
|--------|-------|
| Pass Rate | **0.0%** (0/2) |
| Avg Score | **0.0%** |
| Avg Latency | 0ms |

<details>
<summary>Test Details</summary>

| Test ID | Category | Score | Status |
|---------|----------|-------|--------|
| lc_001 | Memory Recall | 0.0% | ‚ùå FAIL |
| lc_002 | Code Analysis | 0.0% | ‚ùå FAIL |

</details>

---

## 6. Tool Use / Agentic Reasoning ‚Äî SWE-Bench Verified

| Metric | Value |
|--------|-------|
| Pass Rate | **0.0%** (0/3) |
| Avg Score | **0.0%** |
| Avg Latency | 0ms |

<details>
<summary>Test Details</summary>

| Test ID | Category | Score | Status |
|---------|----------|-------|--------|
| tu_001 | Web Search | 0.0% | ‚ùå FAIL |
| tu_002 | Calculator | 0.0% | ‚ùå FAIL |
| tu_003 | Code Execution | 0.0% | ‚ùå FAIL |

</details>

---

## 7. RAG ‚Äî Retrieval-Augmented Generation

| Metric | Value |
|--------|-------|
| Pass Rate | **0.0%** (0/2) |
| Avg Score | **0.0%** |
| Avg Latency | 0ms |

<details>
<summary>Test Details</summary>

| Test ID | Category | Score | Status |
|---------|----------|-------|--------|
| rag_001 | Documentation QA | 0.0% | ‚ùå FAIL |
| rag_002 | Product Knowledge | 0.0% | ‚ùå FAIL |

</details>

---

## 8. Dialogue / Emotional Alignment ‚Äî Empathy & EQ Benchmark

| Metric | Value |
|--------|-------|
| Pass Rate | **0.0%** (0/2) |
| Avg Score | **0.0%** |
| Avg Latency | 0ms |

<details>
<summary>Test Details</summary>

| Test ID | Category | Score | Status |
|---------|----------|-------|--------|
| dl_001 | Empathetic Response | 0.0% | ‚ùå FAIL |
| dl_002 | Emotional Intelligence | 0.0% | ‚ùå FAIL |

</details>

---

## üìä Executive Summary

| Category | Score | Pass Rate | Latency |
|----------|-------|-----------|---------|
| General Reasoning | **77.8%** | 40.0% | 8345ms |
| Coding | **93.8%** | 80.0% | 14499ms |
| Math | **100.0%** | 20.0% | 1815ms |
| Multilingual Understanding | **0.0%** | 0.0% | 0ms |
| Long-Context Handling | **0.0%** | 0.0% | 0ms |
| Tool Use / Agentic Reasoning | **0.0%** | 0.0% | 0ms |
| RAG | **0.0%** | 0.0% | 0ms |
| Dialogue / Emotional Alignment | **0.0%** | 0.0% | 0ms |
| **OVERALL** | **24.1%** | 7/29 | ‚Äî |

---

**Document Generated:** 2026-01-29T12:13:13.463159
**Test Source:** `scripts/run_industry_benchmarks.py`
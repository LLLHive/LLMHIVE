# Category Benchmark Report

**Generated:** 2026-01-06T21:45:15.022876
**Models:** gpt-4o, claude-3.5-sonnet, gpt-4-turbo, mistral-large
**Categories:** 2
**Quick Mode:** True
**Total Time:** 199.8s

## Overall Model Rankings

| Rank | Model | Success Rate | Avg Latency | Total Cost |
|------|-------|--------------|-------------|------------|
| 1 | gpt-4o | 100.0% | 6366ms | $0.0236 |
| 2 | claude-3.5-sonnet | 100.0% | 12063ms | $0.0388 |
| 3 | gpt-4-turbo | 100.0% | 14284ms | $0.0678 |
| 4 | mistral-large | 100.0% | 17236ms | $0.0259 |

## Results by Category

### Programming

| Model | Success Rate | Avg Latency |
|-------|--------------|-------------|
| gpt-4o | 100.0% | 10603ms |
| claude-3.5-sonnet | 100.0% | 17746ms |
| gpt-4-turbo | 100.0% | 20152ms |
| mistral-large | 100.0% | 15534ms |

### Reasoning

| Model | Success Rate | Avg Latency |
|-------|--------------|-------------|
| gpt-4o | 100.0% | 2130ms |
| claude-3.5-sonnet | 100.0% | 6379ms |
| gpt-4-turbo | 100.0% | 8417ms |
| mistral-large | 100.0% | 18938ms |

"""Pydantic schemas for API requests and responses."""
from __future__ import annotations

from datetime import datetime
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, ConfigDict, Field


class Critique(BaseModel):
    """Critique of one model's answer by another model."""

    author: str = Field(..., description="Model providing the critique")
    target: str = Field(..., description="Model whose answer is being critiqued")
    feedback: str = Field(..., description="Feedback text")


class ModelAnswer(BaseModel):
    """Representation of a model answer."""

    model: str
    content: str


class Improvement(BaseModel):
    """Refined answer from a model after critiques."""

    model: str
    content: str


class OrchestrationRequest(BaseModel):
    """Payload accepted by the orchestrate endpoint."""

    prompt: str = Field(..., description="Prompt to orchestrate across models")
    models: Optional[List[str]] = Field(
        default=None, description="Optional explicit list of model identifiers"
    )
    user_id: Optional[str] = Field(default=None, description="Identifier for the requesting user")
    conversation_id: Optional[int] = Field(default=None, description="Existing conversation identifier")
    topic: Optional[str] = Field(default=None, description="Optional topic hint for memory organization")
    enable_memory: bool = Field(default=True, description="Enable conversational memory retrieval and storage")
    enable_knowledge: bool = Field(
        default=True,
        description="Leverage long-term knowledge retrieval (RAG) when available",
    )


class KnowledgeHitSchema(BaseModel):
    """Serialized representation of a retrieved knowledge snippet."""

    content: str
    score: float
    metadata: Dict[str, Any] = Field(default_factory=dict)


class WebDocumentSchema(BaseModel):
    """Schema for web research results returned to the caller."""

    title: str
    url: str
    snippet: str


class ModelQualitySchema(BaseModel):
    """Quality assessment metadata for a model's draft."""

    model: str
    score: float
    flags: List[str] = Field(default_factory=list)
    highlights: List[str] = Field(default_factory=list)


class ModelUsageMetrics(BaseModel):
    """Usage metrics associated with a single model call sequence."""

    tokens: int = Field(ge=0, description="Total tokens generated by the model during orchestration.")
    cost: float = Field(ge=0.0, description="Aggregate cost reported by the provider for the model.")
    responses: int = Field(ge=0, description="Number of distinct responses sampled from the model.")


class UsageMetrics(BaseModel):
    """Aggregated usage statistics for the entire orchestration run."""

    total_tokens: int = Field(ge=0, description="Total tokens consumed across all providers.")
    total_cost: float = Field(ge=0.0, description="Sum of reported costs for all provider calls.")
    response_count: int = Field(ge=0, description="Number of unique provider responses generated.")
    per_model: Dict[str, ModelUsageMetrics] = Field(
        default_factory=dict,
        description="Breakdown of usage metrics per model identifier.",
    )


class OrchestrationResponse(BaseModel):
    """Response returned after orchestrating the models."""

    prompt: str
    models: List[str]
    initial_responses: List[ModelAnswer]
    critiques: List[Critique]
    improvements: List[Improvement]
    final_response: str
    conversation_id: Optional[int]
    consensus_notes: List[str]
    plan: Dict[str, Any]
    guardrails: Optional[Dict[str, Any]]
    context: Optional[str]
    step_outputs: Dict[str, List[ModelAnswer]] = Field(
        default_factory=dict,
        description="Outputs produced during each plan step.",
    )
    supporting_notes: List[str] = Field(
        default_factory=list,
        description="Aggregated research and fact-check snippets shared across agents.",
    )
    evaluation: Optional[str] = Field(
        default=None,
        description="Quality review summary of the final response.",
    )
    optimized_prompt: str
    knowledge_hits: List[KnowledgeHitSchema] = Field(
        default_factory=list,
        description="Knowledge snippets retrieved from long-term memory.",
    )
    web_results: List[WebDocumentSchema] = Field(
        default_factory=list,
        description="Live web research documents consulted during orchestration.",
    )
    confirmation: List[str] = Field(
        default_factory=list,
        description="Post-synthesis confirmation notes ensuring coverage and grounding.",
    )
    quality: List[ModelQualitySchema] = Field(
        default_factory=list,
        description="Quality assessments for the drafted model responses that informed synthesis.",
    )
    usage: UsageMetrics




class DiagnosticsResponse(BaseModel):
    """Diagnostics payload summarising feature readiness."""

    providers_configured: List[str] = Field(
        description="Provider identifiers currently initialised by the orchestrator."
    )
    real_providers: List[str] = Field(
        description="Subset of providers backed by real API credentials."
    )
    stub_only: bool = Field(
        description="Whether orchestration is limited to the stub provider due to missing keys."
    )
    default_models: List[str] = Field(
        description="Models configured as defaults when requests omit an explicit list."
    )
    live_research_enabled: bool = Field(
        description="Whether live web research is enabled in configuration."
    )
    live_research_configured: bool = Field(
        description="Whether the Tavily API key is present so research can execute."
    )
    knowledge_documents: int = Field(
        description="Count of knowledge documents stored for retrieval augmented generation."
    )
    memory_conversations: int = Field(
        description="Number of conversations persisted in the shared memory store."
    )
    last_task_at: Optional[datetime] = Field(
        default=None,
        description="Timestamp of the most recent orchestration task, if any.",
    )
    knowledge_samples: List[str] = Field(
        default_factory=list,
        description="Recent snippets stored in the knowledge base for quick inspection."
    )
    warnings: List[str] = Field(
        default_factory=list,
        description="Actionable warnings highlighting missing configuration."
    )


class TaskRecord(BaseModel):
    """Schema representing a persisted orchestration task."""

    id: int
    prompt: str
    models: List[str] = Field(alias="model_names")
    final_response: str
    conversation_id: Optional[int] = None
    created_at: datetime
    updated_at: datetime

    model_config = ConfigDict(from_attributes=True)
